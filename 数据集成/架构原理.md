## Integration 平台架构原理

数据和元数据都是源服务器的一部分。事务日志读取器位于 Integration 服务器上，基于数据行和日志的过滤和压缩在 Integration 服务器上运行。
在初始化加载过程中，Integration 服务器读取一个经过过滤的行数据流, 将它们传递给转换进程进行进一步处理，然后将结果写入到目标数据源中。
CDC 进程获得一个经过过滤的事件、数据增量或事务日志文件的元数据。在转发到目标数据源之前，缓存所有的数据更新。在初始化加载过程中，发生在事务处理中，CDC也缓存所有的更新，直到所有受影响的表都被加载完毕。

### 数据同步形式

#### 单数据同步任务
每个实例的表同步活动都由一个同步任务组成。我们使用图形可视化在操作面板上以拖拽的方式完成任务的创建。在定义一个任务时需指定：
①源数据库和目标数据库
②待同步的源表和目标表

当一个任务被定义完成，你可以部署、运行这个任务。Integration 平台激活CDC数据处理，自动从源表采集数据，并加载到目标表。使用操作面板上，你可以停止、重启这个同步任务，也可以对这个任务的执行过程进行监控。

#### 多数据同步任务并行执行
可以一次定义和执行多个数据同步任务，多个任务之间相互独立运行，没有影响。
多任务适用于以下数据同步场景： 
    ①有多个源数据库和目标数据库 
    ②有多个源表和目标表
    ③有相同的源表，但有不同的数据抽取条件


#### 全量加载和CDC增量加载进程
全量加载进程在目标数据库端创建一个文件或者表，不像 CDC 进程，全量加载进程一次性加载整个表或文件的数据。
源表主要在加载过程中用来更新活动，然而并不需要在源端停止处理进程。只要加载进程启动，Integration 平台会自动开始CDC进程，直到整个表加载完毕，才将增量数据更新到目标端。因为在全量加载过程中进行增量更新可能会导致数据不一致的情况发生。而在加载过程中，Integration 平台保证了目标端数据的一致性和完整性。
如果加载进程出现故障问题而中断，当重启时，它将继续执行加载处理。
你能够添加一个新表到现有的目标端，而不需要重新加载现有的表。同时，能够更新多个不同的目标表。
CDC进程从源数据库端采集增量数据或元数据，以实时地方式将增量数据写入到目标端。CDC进程采集和应用变更数据以单个提交事务为基本单元，这也保证了在目标数据库端的事务完整性问题。只要数据加载进程启用，CDC将为文件或目标表进行处理。 
CDC通过读取源端数据库的Redo日志文件，对于每个事务处理，进一步组合数据条目。如果CDC进程在一定的时间内没有将数据更新到目标数据库，它将把数据持久化到Kafka服务器中，不需要重新读取源端的DBMS log日志，这样避免了重复工作，节约了大量的时间。 
    
①全量加载（以Hashdata为例）
全量加载被用于在目标端创建一个全新的数据仓库，从源端数据库表全量并发加载数据。高速数据抽取通过源端数据库进行初始化, 然后gpfdist和缓存加载文件用于高速加载数据进入 Hashdata，下图是全量加载数据到 Hashdata 数据仓库的架构


首次运行全量加载数据到 Hashdata 目标表是将需要同步的数据写成CSV文件,并放到文件夹下。CSV文件顺序命名, 例如loadNNNN, NNNN 是从0开始的递增号。
CSV文件的最大大小自己设置。当CSV文件达到最大大小时，它就重命名，并拷贝到加载文件夹。然后通过gpfdist工具进行读取，执行一个 SQL 语句来加载数据到目标表。一旦文件加载完成,则文件将被删除。
②增量加载
对于增量数据加载, Integration 平台使用了基于日志的CDC采集的方式.在CDC同步过程中, Integration 解析从源数据库采集的SQL语句, 提取SQL中的数据值, 重新拼装SQL语句, 创建了一个外表用来执行SQL语句到目标表。下图展示了增量加载数据到 Hashdata 数据仓库的整体架构

追加更新到目标数据库
事务追加模式：
在这个模式下，Hashdata 数据仓库写入所有的更新记录到 CSV 文件作为 DML 语句。当一个文件准备好后，Hashdata 数据仓库创建一个外表，使用 gpfdist 服务器从文件读取变更量，然后执行文件中的 DML语句。当变更追加完后，删除文件。
批量追加模式：
在这个模式下，Hashdata 数据仓库仅仅把增量数据写入到 CSV 文件中。当一个文件准备好后，Hashdata 数据创建一个外表，使用 gpdist 服务器从文件中读取增量数据到临时表。然后增量数据被追加到目标表。当执行完毕后，文件被删除。

### 数据同步方式
#### 一对一同步
在一对一拓扑中，有一个源端数据库和一个目标端数据库。当源端和目标端是唯一的，Hashdata 将保证事务的一致性和完整性。
#### 一对多同步
一对多拓扑中，有一个源端数据库和多个目标端数据库。Integration 平台在创建任务时，可以添加多个目标数据端到任务，一个数据源端可以将数据发送给多个目标端数据库。
多对一拓扑中，有多个源端数据库和一个目标端数据库。Integration 平台在创建任务时，可以添加多个数据源端到任务，多个数据源的数据是独立同步，互相不影响。数据流通过增强和中间层处理可以合并后写入到目标数据库。
一对多和多对一拓扑被称为星型拓扑，一般不允许循环和多路径传播数据更新。星型拓扑是非循环的有向图。
